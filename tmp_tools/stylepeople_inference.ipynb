{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stylepeople_inference.ipynb","provenance":[],"collapsed_sections":["FTcc6OYCNKE3","BTBusqs8NXsL","bR6sMIJPOC7_"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# StylePeople inference code to fit neural textures to images\n","\n","Please download the archive with data from [Google Drive](https://drive.google.com/drive/folders/1-Rzn0fR4Rq2VKS7EUg8hCdJwFe4niNJr) under `drive_path/stylepeople_data`\n","\n","To infer a neural texture for new data samples, run the following installations and execute the last cell"],"metadata":{"id":"MUV83x6fKNRy"}},{"cell_type":"markdown","source":["## Setup : mouting drive and installations"],"metadata":{"id":"FTcc6OYCNKE3"}},{"cell_type":"code","metadata":{"id":"iYznZT_WehuQ"},"source":["### Mount google drive if available\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    drive_path = '/content/drive/MyDrive/master_thesis/'\n","    in_colab = True\n","except:\n","    drive_path = ''\n","    in_colab = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rq1dDUk42TdV"},"source":["### Install all StylePeople's dependecies : see https://github.com/saic-vul/style-people/blob/main/docker/Dockerfile\n","import os\n","\n","# Install stylepeople, rasterizer and requirements\n","!git clone https://github.com/saic-vul/style-people.git\n","!pip install git+https://github.com/rmbashirov/minimal_pytorch_rasterizer\n","!pip --no-cache-dir install -r style-people/requirements.txt\n","\n","# Install conda\n","!wget --quiet https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh -O ~/miniconda.sh\n","!chmod +x ~/miniconda.sh\n","!~/miniconda.sh -b -p ~/miniconda && \\\n","!rm ~/miniconda.sh && \\\n","!conda clean -ya\n","\n","!conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n","\n","os.environ['PYTHONDONTWRITEBYTECODE'] = '1'\n","os.environ['PYTHONUNBUFFERED'] = '1'\n","\n","# Install nvdiffrast plugin\n","!git clone https://github.com/NVlabs/nvdiffrast\n","\n","!apt-get update && apt-get install -y \\\n","    pkg-config \\\n","    libglvnd0 \\\n","    libgl1 \\\n","    libglx0 \\\n","    libegl1 \\\n","    libgles2 \\\n","    libglvnd-dev \\\n","    libgl1-mesa-dev \\\n","    libegl1-mesa-dev \\\n","    libgles2-mesa-dev\n","\n","os.environ['LD_LIBRARY_PATH'] = '/usr/lib64:$LD_LIBRARY_PATH'\n","\n","os.environ['NVIDIA_VISIBLE_DEVICES'] = 'all'\n","os.environ['NVIDIA_DRIVER_CAPABILITIES'] = 'compute,utility,graphics'\n","\n","os.environ['PYOPENGL_PLATFORM'] = 'egl'\n","\n","!cp nvdiffrast/docker/10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json\n","\n","%cd nvdiffrast/\n","!pip install .\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setup : adapt the code to our files paths"],"metadata":{"id":"BTBusqs8NXsL"}},{"cell_type":"code","metadata":{"id":"YYS9vp1BjRp0","executionInfo":{"status":"ok","timestamp":1646597464535,"user_tz":-60,"elapsed":362,"user":{"displayName":"Maxime Raafat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11000288540627124139"}}},"source":["###Â Replace string with another one in a file\n","def replace_string(filename:str, to_replace:str, replacement:str):\n","    with open(filename, 'r') as f:\n","        filedata = f.read()\n","\n","    filedata = filedata.replace(to_replace, replacement)\n","\n","    with open(filename, 'w') as f:\n","        f.write(filedata)\n","\n","    return"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cvxnfvxm0x16","executionInfo":{"status":"ok","timestamp":1646597465940,"user_tz":-60,"elapsed":291,"user":{"displayName":"Maxime Raafat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11000288540627124139"}}},"source":["### Comment some lines in a file\n","from typing import List\n","\n","def comment_lines(filename:str, replace_lines:List[int]):\n","    with open(filename, 'r') as f:\n","        lines = f.readlines()\n","\n","    for n, line in enumerate(lines):\n","        for replace in replace_lines:\n","            if(n == replace - 1):\n","                commented_line = '#' + line\n","                lines[n] = commented_line\n","\n","    with open(filename, 'w') as f:\n","        f.write(''.join(lines))\n","\n","    return"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["### Replace 'data/' with 'stylepeople_data/' in all files : stylepeople_data/ = https://drive.google.com/drive/folders/1-Rzn0fR4Rq2VKS7EUg8hCdJwFe4niNJr\n","datapath1 = drive_path + 'stylepeople_data/'\n","datapath2 = drive_path + 'stylepeople_data'\n","\n","file_list = ['inference_module/inferer.py', 'render_person.py', 'sample_new_textures.py', 'utils/demo.py', 'utils/uv_renderer.py', 'infer_texture.py']\n","\n","for f in file_list:\n","    filename = 'style-people/' + f\n","    replace_string(filename, to_replace='data/', replacement=datapath1)\n","\n","replace_string(filename='style-people/inference_module/config.yaml', to_replace='data', replacement=datapath2)\n","replace_string(filename='style-people/utils/smplx_models.py', to_replace='.pkl', replacement='.npz')\n","replace_string(filename='style-people/infer_texture.py', to_replace='inference_module/', replacement='style-people/inference_module/')\n","replace_string(filename='style-people/utils/demo.py', to_replace='/checkpoints/', replacement='/checkpoint/')\n","replace_string(filename='style-people/inference_module/inferer.py', to_replace='\"checkpoints\"', replacement='\"checkpoint\"')\n","replace_string(filename='style-people/inference_module/runner.py', to_replace='kornia.resize', replacement='kornia.geometry.transform.resize')\n","\n","### In style-people/sample_new_textures.py, comment lines 15, 16, 17 and 19\n","comment_lines(filename='style-people/infer_texture.py', replace_lines=[14, 15, 16, 18])"],"metadata":{"id":"NtkSccoaqPzZ","executionInfo":{"status":"ok","timestamp":1646597466849,"user_tz":-60,"elapsed":2,"user":{"displayName":"Maxime Raafat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11000288540627124139"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["In `style-people/inference_module/criterion.py`, add the code from the following cell after line 32"],"metadata":{"id":"6NoyVeiYN2XJ"}},{"cell_type":"code","source":["'''\n","fct = 1 # sampling factor\n","while True:\n","    try:\n","        loss_not_reduced = self.lpips(pred.contiguous(), target.contiguous())\n","        break\n","    except RuntimeError:\n","        pred = pred[:,:,::fct,::fct]\n","        target = target[:,:,::fct,::fct]\n","        fct += 1\n","    if fct == 6:\n","        raise RuntimeError('CUDA out of memory.')\n","'''"],"metadata":{"id":"kIMwibtwph_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Infer a neural texture"],"metadata":{"id":"bR6sMIJPOC7_"}},{"cell_type":"code","source":["### Infer a neural texture for a given set of images\n","\n","SMPLX_MODEL_PATH = drive_path + 'smplx'\n","\n","# ZJU MoCap\n","SAVEPATH = drive_path + 'zju_mocap_1_frame/inference_data'\n","DATAPATH = drive_path + 'zju_mocap_1_frame/pickle_data'\n","\n","# People Snapshot\n","'''\n","subject_path = drive_path + 'stylepeople_snapchot/people_snapshot_f1c/'\n","SAVEPATH = subject_path + 'inferstyle1'\n","DATAPATH = subject_path + 'styledata1'\n","'''\n","\n","# Azure People\n","'''\n","subject = 'azure_01'\n","sampels_path = drive_path + 'stylepeople_data/inference_samples/'\n","SAVEPATH = drive_path + 'azure_inference/' + subject\n","DATAPATH = sampels_path + subject\n","'''\n","\n","%run style-people/infer_texture.py --input_path $DATAPATH --texture_out_dir $SAVEPATH --smplx_model_dir $SMPLX_MODEL_PATH"],"metadata":{"id":"v5pDERs7nA5e"},"execution_count":null,"outputs":[]}]}