{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgJYmow2NB91"
   },
   "outputs": [],
   "source": [
    "### Install all dependecies\n",
    "\n",
    "# pytorch3d\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d=False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "        version_str=\"\".join([\n",
    "            f\"py3{sys.version_info.minor}_cu\",\n",
    "            torch.version.cuda.replace(\".\",\"\"),\n",
    "            f\"_pyt{pyt_version_str}\"\n",
    "        ])\n",
    "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
    "\n",
    "\n",
    "# cleanup\n",
    "!rm -rf 1.10.0.tar.gz cub-1.10.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8owkzySKcO6c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from typing import Union\n",
    "\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    PerspectiveCameras,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    AmbientLights,\n",
    "    BlendParams,\n",
    "    TexturesUV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unsdLa2kUaEY"
   },
   "outputs": [],
   "source": [
    "### Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYT9fX9HY8ae"
   },
   "outputs": [],
   "source": [
    "### Construct textured mesh for a specific subject and pose\n",
    "\n",
    "def construct_mesh(subject:int, pose:str, default_mesh_path:str):\n",
    "    default_mesh = load_obj(default_mesh_path, load_textures=False)\n",
    "\n",
    "    verts_uvs = default_mesh[2].verts_uvs.to(device).unsqueeze(0)\n",
    "    faces_uvs = default_mesh[1].textures_idx.to(device).unsqueeze(0)\n",
    "\n",
    "    texture_filename = 'subject_%d/body/%s/appearance/median_map.png' % (subject, pose)\n",
    "    texture_img = read_image(texture_filename)\n",
    "    texture_img = torch.moveaxis(texture_img, 0, 2).unsqueeze(0).float() * 1.0/255\n",
    "    texture_uv = TexturesUV(maps=texture_img, faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
    "\n",
    "    verts_filename = 'subject_%d/body/%s/reconstruction/smpl_vertex.txt' % (subject, pose)\n",
    "    mesh_verts = torch.Tensor( np.loadtxt(verts_filename) ).to(device).unsqueeze(0)\n",
    "    mesh_faces = default_mesh[1].verts_idx.to(device).unsqueeze(0)\n",
    "\n",
    "    mesh = Meshes(mesh_verts, mesh_faces, texture_uv)\n",
    "\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract camera calibration parameters for a subject\n",
    "# Returns the camera ids and the corresponding parameters\n",
    "\n",
    "def camera_calibration(subject:int, calibration:str='intrinsic'):\n",
    "    assert( calibration in ['intrinsic', 'extrinsic', 'project'] ), \"calibration needs to be one of 'intrinsic', 'extrinsic' or 'project'\"\n",
    "\n",
    "    filename = 'subject_%d/body/%s.txt' % (subject, calibration)\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()[3:]\n",
    "\n",
    "    if calibration == 'intrinsic':\n",
    "        rows = 3\n",
    "        cols = 3\n",
    "    elif calibration == 'extrinsic':\n",
    "        rows = 4\n",
    "        cols = 3\n",
    "    elif calibration == 'project':\n",
    "        rows = 3\n",
    "        cols = 4\n",
    "\n",
    "    camera_id = [int(id[1:]) for id in lines[::rows+1]]\n",
    "\n",
    "    parameters = lines.copy()\n",
    "    del parameters[0::rows+1]\n",
    "    parameters = torch.from_numpy(np.loadtxt(parameters))\n",
    "    parameters = parameters.reshape(len(camera_id), rows, cols)\n",
    "\n",
    "    return camera_id, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract camera matrices for a subject and camera\n",
    "\n",
    "def get_camera_parameters(subject:int, camera_index:int):\n",
    "    assert(camera_index in range(107)), 'camera_index must be an integer in between 0 and 106'\n",
    "    intr_id, intrinsic = camera_calibration(subject, calibration='intrinsic')\n",
    "    extr_id, extrinsic = camera_calibration(subject, calibration='extrinsic')\n",
    "    proj_id, projection = camera_calibration(subject, calibration='project')\n",
    "    # intr_id = extr_id = proj_id\n",
    "\n",
    "    cam = intr_id.index(camera_index)\n",
    "\n",
    "    C = extrinsic[cam][0]\n",
    "    R = extrinsic[cam][1:]\n",
    "    T = - torch.matmul(R, C)\n",
    "    K = intrinsic[cam]\n",
    "\n",
    "    R = R.T.unsqueeze(0)\n",
    "    T = T.unsqueeze(0)\n",
    "\n",
    "    f = torch.tensor((K[0,0], K[1,1]), dtype=torch.float32).unsqueeze(0)\n",
    "    p = torch.tensor((K[0,2], K[1,2]), dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return R, T, f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get renderer\n",
    "\n",
    "def get_renderer(cameras:pytorch3d.renderer.cameras, image_size:Union[int, tuple[int, int]]=(360, 640), device=device):\n",
    "    raster_settings = RasterizationSettings(\n",
    "        image_size=image_size,\n",
    "        blur_radius=0.0,\n",
    "        faces_per_pixel=1,\n",
    "        max_faces_per_bin=10000\n",
    "    )\n",
    "\n",
    "    blend_params = BlendParams(background_color=(0, 0, 0))\n",
    "    lights = AmbientLights(device=device)\n",
    "\n",
    "    renderer = MeshRenderer(\n",
    "        rasterizer=MeshRasterizer(\n",
    "            cameras=cameras, \n",
    "            raster_settings=raster_settings\n",
    "        ),\n",
    "        shader=SoftPhongShader(\n",
    "            device=device, \n",
    "            cameras=cameras,\n",
    "            lights=lights,\n",
    "            blend_params=blend_params\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VYu_EyKeHYRi"
   },
   "outputs": [],
   "source": [
    "subject = 1\n",
    "pose = '00000001'\n",
    "obj_mesh = 'smplx/text_uv_coor_smpl.obj'\n",
    "\n",
    "humbi_smpl_mesh = construct_mesh(subject, pose, obj_mesh)\n",
    "\n",
    "camera_idx = 73 # camera view to render\n",
    "R, T, f, p = get_camera_parameters(subject, camera_idx)\n",
    "\n",
    "img_size = (1080, 1920)\n",
    "cameras = PerspectiveCameras(focal_length=-f, principal_point=p, R=R, T=T, in_ndc=False, image_size=(img_size,), device=device)\n",
    "\n",
    "render_img_size = (270, 480) # render resolution\n",
    "renderer = get_renderer(cameras, render_img_size, device)\n",
    "render = renderer(humbi_smpl_mesh).detach()\n",
    "rgb_render = render[0, ..., :3]\n",
    "\n",
    "photo_path = 'subject_%s/body/%s/image/image%s.jpg' % (subject, pose, str(camera_idx).zfill(7))\n",
    "photo = read_image(photo_path)\n",
    "\n",
    "rescale = transforms.Resize(render_img_size)\n",
    "resized_photo = rescale(photo).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(rgb_render.cpu().numpy())\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(resized_photo.cpu().numpy())\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pointcloud_rendering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
