{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWgk3VHgK1KT"
   },
   "outputs": [],
   "source": [
    "### Mount google drive if available\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/MyDrive/term_paper/'\n",
    "    in_colab = True\n",
    "except:\n",
    "    drive_path = ''\n",
    "    in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnQvkg9oLDaW"
   },
   "outputs": [],
   "source": [
    "### Install all dependecies\n",
    "\n",
    "# pytorch3d\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d=False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "        version_str=\"\".join([\n",
    "            f\"py3{sys.version_info.minor}_cu\",\n",
    "            torch.version.cuda.replace(\".\",\"\"),\n",
    "            f\"_pyt{pyt_version_str}\"\n",
    "        ])\n",
    "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
    "\n",
    "\n",
    "# smplx\n",
    "need_smplx=False\n",
    "try:\n",
    "    import smplx\n",
    "except ModuleNotFoundError:\n",
    "    need_smplx=True\n",
    "\n",
    "if need_smplx:\n",
    "    !pip install smplx\n",
    "    !git clone https://github.com/vchoutas/smplx\n",
    "    %cd smplx\n",
    "    !python setup.py install\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "# bps\n",
    "need_bps=False\n",
    "try:\n",
    "    import bps\n",
    "except ModuleNotFoundError:\n",
    "    need_bps=True\n",
    "\n",
    "if need_bps:\n",
    "    !pip install git+https://github.com/sergeyprokudin/bps\n",
    "\n",
    "\n",
    "# chamfdist\n",
    "if torch.cuda.is_available():\n",
    "    need_chamferdist=False\n",
    "    try:\n",
    "        import chamferdist\n",
    "    except ModuleNotFoundError:\n",
    "        need_chamferdist=True\n",
    "    \n",
    "    if need_chamferdist:\n",
    "        !pip install chamferdist\n",
    "\n",
    "\n",
    "#Â cleanup\n",
    "!rm -rf 1.10.0.tar.gz cub-1.10.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpYs_GQxLMLg"
   },
   "outputs": [],
   "source": [
    "### Download data for subject 1\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request as request\n",
    "\n",
    "attributes = ['body', 'body_texture', 'pointcloud']\n",
    "pointcloud_subjects = [[1, 80], [81, 140], [141, 220], [221, 300], [301, 380], [381, 453]]\n",
    "\n",
    "subject = 1\n",
    "\n",
    "# Determine pointcloud interval for current subject\n",
    "pointcloud_zip = 'subject_'\n",
    "for i in pointcloud_subjects:\n",
    "    if subject >= i[0] and subject <= i[1]:\n",
    "        pointcloud_zip += '%d_%d.zip' % (i[0], i[1])\n",
    "\n",
    "for attr in attributes:\n",
    "    if attr != 'pointcloud':\n",
    "        url = os.path.join('https://humbi-dataset.s3.amazonaws.com', attr + '_subject', 'subject_%d.zip' % subject)\n",
    "        path = '%s_subject_%d.zip' % (attr, subject)\n",
    "        request.urlretrieve(url, path)\n",
    "        downloaded_zip = zipfile.ZipFile(path)\n",
    "        downloaded_zip.extractall() # !unzip downloaded_zip\n",
    "        os.remove(path)\n",
    "\n",
    "    else:\n",
    "        pointcloud_url = 'https://humbi-dataset.s3.amazonaws.com/pointcloud/' + pointcloud_zip\n",
    "        pointcloud_path = 'pointcloud_' + pointcloud_zip\n",
    "        request.urlretrieve(pointcloud_url, pointcloud_path)\n",
    "        downloaded_zip = zipfile.ZipFile(pointcloud_path)\n",
    "        for filename in downloaded_zip.namelist():\n",
    "            if filename.startswith('subject_%d/' % subject):\n",
    "                downloaded_zip.extract(filename)\n",
    "        os.remove(pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kRZXR-GLGwZ"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pointcloud_fitting\n",
    "importlib.reload(pointcloud_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G1VuL7KzTBc"
   },
   "outputs": [],
   "source": [
    "import smplx\n",
    "from utils.plot_structures import plot_structure\n",
    "from pointcloud_fitting import pointcloud_list, fit_pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a5fL4J4LJoP"
   },
   "outputs": [],
   "source": [
    "### Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r4iaSRfLbmw"
   },
   "outputs": [],
   "source": [
    "### Construct and plot pointclouds for chosen subject\n",
    "\n",
    "subject = 1\n",
    "\n",
    "# select poses\n",
    "poses = ['00000001', '00000017', '00000033', '00000041', '00000089']\n",
    "\n",
    "# select all poses\n",
    "'''\n",
    "poses_path = 'subject_%d/body/' % subject\n",
    "for pose in sorted(os.listdir(poses_path)):\n",
    "    pose_path = os.path.join(poses_path, pose)\n",
    "    if os.path.isdir(pose_path):\n",
    "        poses.append(pose)\n",
    "'''\n",
    "\n",
    "# construct pointclouds\n",
    "try:\n",
    "    humbi_pointclouds\n",
    "except NameError:\n",
    "    print(\"Load pointclouds\")\n",
    "    humbi_pointclouds = pointcloud_list(subject, poses, device)\n",
    "\n",
    "# plotting\n",
    "plot_structure(humbi_pointclouds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWKRXnv2LnVJ"
   },
   "outputs": [],
   "source": [
    "smplx_model_path = drive_path + 'smplx'\n",
    "smplx_model = smplx.SMPLXLayer(smplx_model_path, gender='neutral').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA4Q64IVLpS5"
   },
   "outputs": [],
   "source": [
    "# fit pointclouds\n",
    "fitting_output = fit_pointclouds(smplx_model, subject, poses, humbi_pointclouds, global_iterations=400, shape_iterations=300)\n",
    "displacements, smplx_visualizations, disps_visualizations, smplx_losses, disps_losses = fitting_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXfcATRpZNOy"
   },
   "outputs": [],
   "source": [
    "plot_structure(disps_visualizations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1ay604Yo4un"
   },
   "outputs": [],
   "source": [
    "smplx_losses_tensor = torch.Tensor().to(device)\n",
    "disps_losses_tensor = torch.Tensor().to(device)\n",
    "for smplx_loss, disps_loss in zip(smplx_losses, disps_losses):\n",
    "    smplx_losses_tensor = torch.cat( (smplx_losses_tensor, smplx_loss.unsqueeze(0)) )\n",
    "    disps_losses_tensor = torch.cat( (disps_losses_tensor, disps_loss.unsqueeze(0)) )\n",
    "\n",
    "min_disps_loss = disps_losses_tensor.median().item() - disps_losses_tensor.std().item()\n",
    "max_disps_loss = disps_losses_tensor.median().item() + disps_losses_tensor.std().item()\n",
    "\n",
    "min_disps_loss, max_disps_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz85Ik04dOiX"
   },
   "outputs": [],
   "source": [
    "displacements_tensor = torch.Tensor().to(device)\n",
    "for disp, loss in zip(displacements, disps_losses):\n",
    "    if min_disps_loss < loss < max_disps_loss:\n",
    "        displacements_tensor = torch.cat( (displacements_tensor, disp.unsqueeze(0)) )\n",
    "\n",
    "avg_disp = torch.mean(displacements_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH_WO9wxTCdL"
   },
   "outputs": [],
   "source": [
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "smplx_faces = torch.Tensor(smplx_model.faces.astype('int')).type(torch.int32).unsqueeze(0).to(device)\n",
    "verts = smplx_model.forward()['vertices'].to(device)\n",
    "init_mesh = Meshes(verts, smplx_faces)\n",
    "\n",
    "displaced_verts = verts + (init_mesh.verts_normals_packed() * avg_disp.unsqueeze(1)).unsqueeze(0)\n",
    "displaced_mesh = Meshes(displaced_verts , smplx_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FrQiVMnfShM"
   },
   "outputs": [],
   "source": [
    "plot_structure([init_mesh, displaced_mesh])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "smplx_fit_pointcloud.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
