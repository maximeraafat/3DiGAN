{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9mjNh_XjB4s"
   },
   "outputs": [],
   "source": [
    "### Mount google drive if available\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/MyDrive/term_paper/'\n",
    "    in_colab = True\n",
    "except:\n",
    "    drive_path = ''\n",
    "    in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgJYmow2NB91"
   },
   "outputs": [],
   "source": [
    "### Install all dependecies\n",
    "\n",
    "# pytorch3d\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d=False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "        version_str=\"\".join([\n",
    "            f\"py3{sys.version_info.minor}_cu\",\n",
    "            torch.version.cuda.replace(\".\",\"\"),\n",
    "            f\"_pyt{pyt_version_str}\"\n",
    "        ])\n",
    "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
    "\n",
    "\n",
    "# smpl-x\n",
    "need_smplx=False\n",
    "try:\n",
    "    import smplx\n",
    "except ModuleNotFoundError:\n",
    "    need_smplx=True\n",
    "\n",
    "if need_smplx:\n",
    "    !pip install smplx\n",
    "    !git clone https://github.com/vchoutas/smplx\n",
    "    %cd smplx\n",
    "    !python setup.py install\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "#Â cleanup\n",
    "!rm -rf 1.10.0.tar.gz cub-1.10.0/ smplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8owkzySKcO6c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import smplx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.vis.plotly_vis import plot_scene\n",
    "from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n",
    "from pytorch3d.structures import Meshes, packed_to_list\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVOrthographicCameras,\n",
    "    PerspectiveCameras,\n",
    "    PointLights,\n",
    "    Materials,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    BlendParams,\n",
    "    TexturesVertex,\n",
    "    TexturesUV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unsdLa2kUaEY"
   },
   "outputs": [],
   "source": [
    "### Setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHJoZ-UcNuiI"
   },
   "outputs": [],
   "source": [
    "### Load SMPL-X model as Pytorch3d mesh\n",
    "\n",
    "# if true, use SMPL object for HUMBI ; otherwise use SMPLX model\n",
    "HUMBI_SMPL = True\n",
    "GENERATED = False\n",
    "\n",
    "if HUMBI_SMPL:\n",
    "    if GENERATED:\n",
    "        TEX_PATH = drive_path + 'generated_maps/generated_images/sample_run_256-generated-87/'\n",
    "    else:\n",
    "        TEX_PATH = drive_path + 'humbi_maps/humbi_body_texture/body_texture_medians/'\n",
    "        subject_subset = ['median_subject_1.png', 'median_subject_2.png', 'median_subject_3.png', 'median_subject_4.png']\n",
    "\n",
    "    OBJ_PATH = drive_path + 'smpl_bodies/text_uv_coor_smpl.obj'\n",
    "\n",
    "    smplx_tex_img = torch.Tensor()\n",
    "\n",
    "    for texture in os.listdir(TEX_PATH):\n",
    "        if GENERATED:\n",
    "            tex_img = read_image(TEX_PATH + texture)\n",
    "            tex_img = torch.moveaxis(tex_img, 0, 2).unsqueeze_(0).float() * 1.0/255\n",
    "            smplx_tex_img = torch.cat((smplx_tex_img, tex_img))\n",
    "        else:\n",
    "            if texture in subject_subset:\n",
    "                tex_img = read_image(TEX_PATH + texture)\n",
    "                tex_img = torch.moveaxis(tex_img, 0, 2).unsqueeze_(0).float() * 1.0/255\n",
    "                smplx_tex_img = torch.cat((smplx_tex_img, tex_img))\n",
    "\n",
    "    mesh = load_obj(OBJ_PATH, load_textures=False)\n",
    "\n",
    "    verts_uvs = mesh[2].verts_uvs.unsqueeze_(0)\n",
    "    verts_uvs = torch.cat([verts_uvs] * smplx_tex_img.shape[0])\n",
    "    faces_uvs = mesh[1].textures_idx.unsqueeze_(0)\n",
    "    faces_uvs = torch.cat([faces_uvs] * smplx_tex_img.shape[0] )\n",
    "\n",
    "    smplx_mesh_verts = mesh[0].unsqueeze_(0)\n",
    "    smplx_mesh_verts = torch.cat([smplx_mesh_verts] * smplx_tex_img.shape[0] )\n",
    "    smplx_mesh_faces = mesh[1].verts_idx.unsqueeze_(0)\n",
    "    smplx_mesh_faces = torch.cat([smplx_mesh_faces] * smplx_tex_img.shape[0])\n",
    "\n",
    "    smplx_texture = TexturesUV(maps=smplx_tex_img, faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
    "\n",
    "else:\n",
    "    SMPLX_MODEL_PATH = drive_path + 'smpl_bodies'\n",
    "\n",
    "    smplx_model = smplx.SMPLXLayer(SMPLX_MODEL_PATH, gender='neutral')\n",
    "\n",
    "    smplx_mesh_verts = smplx_model.forward()['vertices']\n",
    "    smplx_mesh_faces = torch.Tensor(smplx_model.faces.astype('int')).type(torch.int32).unsqueeze(0)\n",
    "    smplx_verts_colors = torch.ones_like(smplx_mesh_verts)\n",
    "    smplx_texture = TexturesVertex(verts_features=smplx_verts_colors)\n",
    "\n",
    "smplx_mesh = Meshes(smplx_mesh_verts, smplx_mesh_faces, smplx_texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wX_ECmoBOXN_"
   },
   "outputs": [],
   "source": [
    "### Plotting function\n",
    "\n",
    "# images : tensor of images\n",
    "# figsize : size of the plot (tuple)\n",
    "# save : is the image being saved (boolean)\n",
    "# path_name : path under which the image will be saved if save=True\n",
    "# wspace and hspace : spacing between images\n",
    "\n",
    "default_path = drive_path + 'generated_maps/generated_images/plot.png'\n",
    "def plotting(images, figsize=(20,20), save=False, path_name=default_path, wspace=0, hspace=0.025):\n",
    "    assert(len(images.shape) == 4), 'tensor must have 4 channels (#images, r, g, b) : consider using tensor.unsqueeze(0)'\n",
    "    dimension = images.shape[0]\n",
    "\n",
    "    x = np.ceil( np.sqrt(dimension) )\n",
    "    y = np.ceil( dimension/x )\n",
    "\n",
    "    if save:\n",
    "      print('The following image will be saved')\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(dimension):\n",
    "        plt.subplot(x,y,i+1)\n",
    "        plt.imshow(images[i].cpu().numpy())\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0.025)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path_name, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5z1OCdyv3W2a"
   },
   "outputs": [],
   "source": [
    "### Image inpainting function\n",
    "\n",
    "# image : image tensor\n",
    "# inpainting_method : inpainting method ('telea' or 'ns')\n",
    "\n",
    "# Return inpainted image as a tensor\n",
    "\n",
    "def inpaint_img(image, inpainting_method='telea'):\n",
    "    assert(inpainting_method == 'telea' or inpainting_method == 'ns'), \"inpainting_method must be one of 'telea' or 'ns' (Navier-Stokes)\"\n",
    "\n",
    "    image = (image * 255).numpy().astype(np.uint8)\n",
    "\n",
    "    dim = image[:,:,0].shape\n",
    "    inpaint_mask = np.zeros(dim, dtype=np.uint8)\n",
    "    mask_condition = (image[:,:,0] == 0) & (image[:,:,1] == 0) & (image[:,:,2] == 0)\n",
    "    inpaint_mask[mask_condition] = 1\n",
    "\n",
    "    # inpainting\n",
    "    method = cv2.INPAINT_TELEA * (inpainting_method=='telea') + cv2.INPAINT_NS * (inpainting_method=='ns')\n",
    "    inpainted_image = cv2.inpaint(image, inpaint_mask, 3, method)\n",
    "\n",
    "    return torch.Tensor(inpainted_image.copy()).float() * 1.0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-izWsr4U7dGG"
   },
   "outputs": [],
   "source": [
    "### TexturesUV inpainting function\n",
    "\n",
    "# textures : TexturesUV object\n",
    "# inpainting_method : inpainting method ('telea' or 'ns')\n",
    "\n",
    "# Return TexturesUV object with inpainted textures\n",
    "\n",
    "def inpaint_texture(textures: TexturesUV, inpainting_method='telea'):\n",
    "    assert(len(textures.maps_padded().shape) == 4), 'tensor must have 4 channels (#images, r, g, b) : consider using tensor.unsqueeze(0)'\n",
    "    dimension = textures.maps_padded().shape[0]\n",
    "\n",
    "    inpainted_textures = textures.clone()\n",
    "    for i in range(dimension):\n",
    "        inpainted_textures._maps_padded[i] = inpaint_img(inpainted_textures.maps_padded()[i], inpainting_method)\n",
    "\n",
    "    return inpainted_textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83LaDCZoCNGN"
   },
   "outputs": [],
   "source": [
    "### If HUMBI_SMPL = True, visualize the loaded texture\n",
    "\n",
    "if HUMBI_SMPL:\n",
    "    plotting( smplx_texture.maps_padded() )\n",
    "\n",
    "    inpainted_smplx_texture = inpaint_texture(smplx_texture)\n",
    "    plotting( inpainted_smplx_texture.maps_padded() )\n",
    "\n",
    "    # plot mapping from vertices to texture for first subject\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    texturesuv_image_matplotlib(smplx_texture[0], subsample=None)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Alg7W7KvPdr8"
   },
   "outputs": [],
   "source": [
    "### Setup pytorch3d mesh renderer\n",
    "\n",
    "def get_mesh_renderer(img_width=1024, img_height=1024, device=device):\n",
    "\n",
    "    raster_settings = RasterizationSettings(\n",
    "        image_size=(img_width, img_height), \n",
    "        blur_radius=0.0, \n",
    "        faces_per_pixel=1,\n",
    "        max_faces_per_bin=10000\n",
    "    )\n",
    "\n",
    "    blend_params = BlendParams(background_color=(0, 0, 0))\n",
    "    lights = PointLights(device=device, location=[[2.0, 2.0, 2.0]])\n",
    "\n",
    "    cameras = PerspectiveCameras().to(device)\n",
    "\n",
    "    mesh_renderer = MeshRenderer(\n",
    "        rasterizer=MeshRasterizer(\n",
    "            cameras=cameras, \n",
    "            raster_settings=raster_settings\n",
    "        ),\n",
    "        shader=SoftPhongShader(\n",
    "            device=device, \n",
    "            cameras=cameras,\n",
    "            lights=lights,\n",
    "            blend_params=blend_params\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return mesh_renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTqtRAX-RXld"
   },
   "outputs": [],
   "source": [
    "### Render test mesh\n",
    "\n",
    "img_width, img_height = 1024, 1024\n",
    "mesh_renderer = get_mesh_renderer(img_width, img_height, device)\n",
    "\n",
    "smplx_mesh = smplx_mesh.to(device)\n",
    "\n",
    "materials = Materials(device=device, specular_color=[[0.0, 0.0, 0.0]], shininess=0.0)\n",
    "\n",
    "dist = 1 # 20\n",
    "azim = 20 # 10\n",
    "elev = 20 # 0\n",
    "# up = ((0, 0, 1), )\n",
    "\n",
    "# R, T = look_at_view_transform(dist=dist, elev=elev, azim=azim, up=up)\n",
    "R, T = look_at_view_transform(dist=dist, elev=elev, azim=azim)\n",
    "\n",
    "if HUMBI_SMPL:\n",
    "    min_y = -0.2 ; max_y = 1.8\n",
    "else:\n",
    "    min_y = -1.4 ; max_y = 0.6\n",
    "\n",
    "# cameras = FoVOrthographicCameras(R=R, T=T).to(device)\n",
    "cameras = FoVOrthographicCameras(min_y=min_y, max_y=max_y, R=R, T=T).to(device)\n",
    "\n",
    "img = mesh_renderer(smplx_mesh, cameras=cameras, materials=materials)[:, :, :, 0:3].detach()\n",
    "\n",
    "plotting(img, figsize=(20,20))\n",
    "\n",
    "if HUMBI_SMPL:\n",
    "    final_render = drive_path + 'generated_maps/generated_images/sample_run_256.png'\n",
    "    plotting(img[0].unsqueeze(0), figsize=(10,10), save=True, path_name=final_render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIpoSXVYx0ru"
   },
   "outputs": [],
   "source": [
    "### Plotly (interactive) visualization\n",
    "\n",
    "# Convert TexturesUV to TexturesVertex\n",
    "def convert_to_textureVertex(textures_uv: TexturesUV, meshes:Meshes, idx: int) -> TexturesVertex:\n",
    "    assert( idx in range( len(meshes.num_verts_per_mesh()) ) ), 'idx needs be an integer between 0 and #subjects'\n",
    "\n",
    "    verts_colors_packed = torch.zeros_like(meshes.verts_packed()).to(device)\n",
    "    verts_colors_packed[meshes.faces_packed()] = textures_uv.faces_verts_textures_packed().to(device)\n",
    "\n",
    "    vertex_shape = meshes.num_verts_per_mesh()[idx].item()\n",
    "\n",
    "    return TexturesVertex( packed_to_list(\n",
    "        verts_colors_packed[idx * vertex_shape : (idx+1) * vertex_shape, :],\n",
    "        meshes.num_verts_per_mesh()[idx] ) )\n",
    "\n",
    "index = 1 #Â subject to visualize\n",
    "vertex_texture = convert_to_textureVertex(smplx_texture, smplx_mesh, index)\n",
    "\n",
    "mesh = Meshes(\n",
    "    verts=smplx_mesh_verts[index, :, :].unsqueeze(0).to(device),   \n",
    "    faces=smplx_mesh_faces[index, :, :].unsqueeze(0).to(device),\n",
    "    textures=vertex_texture\n",
    ")\n",
    "\n",
    "# Render figure\n",
    "fig = plot_scene({\n",
    "    \"Humbi generated texture mapped on SMPL body\": {\n",
    "        \"plot\": mesh\n",
    "        }\n",
    "},)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "smpl_rendering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
