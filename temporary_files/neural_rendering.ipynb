{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weKUr0Ckkv2S"
   },
   "outputs": [],
   "source": [
    "### Mount google drive if available\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/MyDrive/term_paper/'\n",
    "    in_colab = True\n",
    "except:\n",
    "    drive_path = ''\n",
    "    in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgJYmow2NB91"
   },
   "outputs": [],
   "source": [
    "### Install all dependecies\n",
    "\n",
    "# pytorch3d\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d=False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "\n",
    "if need_pytorch3d:\n",
    "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
    "        # We try to install PyTorch3D via a released wheel.\n",
    "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "        version_str=\"\".join([\n",
    "            f\"py3{sys.version_info.minor}_cu\",\n",
    "            torch.version.cuda.replace(\".\",\"\"),\n",
    "            f\"_pyt{pyt_version_str}\"\n",
    "        ])\n",
    "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "    else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
    "        !tar xzf 1.10.0.tar.gz\n",
    "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
    "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
    "\n",
    "\n",
    "# smplx\n",
    "need_smplx=False\n",
    "try:\n",
    "    import smplx\n",
    "except ModuleNotFoundError:\n",
    "    need_smplx=True\n",
    "\n",
    "if need_smplx:\n",
    "    !pip install smplx\n",
    "    !git clone https://github.com/vchoutas/smplx\n",
    "    %cd smplx\n",
    "    !python setup.py install\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "# detectron2\n",
    "need_detectron=False\n",
    "try:\n",
    "    import detectron2\n",
    "except ModuleNotFoundError:\n",
    "    need_detectron=True   \n",
    "\n",
    "if need_detectron:\n",
    "    !git clone https://github.com/facebookresearch/detectron2.git detectron2_repo\n",
    "    !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "\n",
    "# cleanup\n",
    "!rm -rf 1.10.0.tar.gz cub-1.10.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import neural_rendering\n",
    "import utils.smpl_to_smplx\n",
    "import utils.smplx_to_disps\n",
    "import utils.renderers\n",
    "import utils.inpainting\n",
    "importlib.reload(neural_rendering)\n",
    "importlib.reload(utils.smpl_to_smplx)\n",
    "importlib.reload(utils.smplx_to_disps)\n",
    "importlib.reload(utils.renderers)\n",
    "importlib.reload(utils.inpainting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smplx\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.ops import SubdivideMeshes\n",
    "from pytorch3d.renderer import (\n",
    "    PerspectiveCameras,\n",
    "    TexturesUV,\n",
    "    TexturesVertex\n",
    ")\n",
    "\n",
    "from utils.plot_structures import plot_structure\n",
    "from utils.smplx_to_disps import smplx2disps\n",
    "from utils.inpainting import get_disps_inpaint\n",
    "from utils.camera_calibration import get_camera_parameters\n",
    "from utils.renderers import get_renderers\n",
    "from utils.pointrend_segmentation import get_pointrend_segmentation\n",
    "\n",
    "from neural_rendering import neural_renderer, construct_textured_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unsdLa2kUaEY"
   },
   "outputs": [],
   "source": [
    "### Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "pose = '00000025' # T-pose\n",
    "subdivision = False\n",
    "\n",
    "obj_path = drive_path + 'smplx/smplx_uv.obj'\n",
    "subd_obj_path = drive_path + 'smplx/subd_smplx_uv.obj'\n",
    "uv_mask_img = drive_path + 'smplx/smplx_uv.png'\n",
    "\n",
    "save_path = drive_path + 'humbi_smplx'\n",
    "\n",
    "smplx_model_path = drive_path + 'smplx'\n",
    "smplx_model = smplx.SMPLXLayer(smplx_model_path, 'neutral').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not subdivision:\n",
    "    geometry, texture = neural_renderer(smplx_model, subject, pose, 1, obj_path, subdivision, rescale_factor=8, save_path=save_path)\n",
    "else:\n",
    "    geometry, texture = neural_renderer(smplx_model, subject, pose, 30, subd_obj_path, subdivision, rescale_factor=2, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract geometry\n",
    "global_orient, transl, body_pose, left_hand_pose, right_hand_pose, jaw_pose, expression, betas, scale, verts_disps = geometry\n",
    "\n",
    "# Store geometry into displacements along normals + get displaced and initial mesh\n",
    "learned_geometry, init_mesh, displaced_mesh = smplx2disps(smplx_model, betas, scale, verts_disps, subdivision, smoothing=2)\n",
    "\n",
    "# Construct displacement map by interpolating values between uv vertex coordinates (inpainting) : for now only available for no subdivision!\n",
    "if not subdivision:\n",
    "    displacement_map, mask = get_disps_inpaint(subject, learned_geometry, obj_path, uv_mask_img, mask_disps=True)\n",
    "\n",
    "plot_structure([init_mesh, displaced_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not subdivision:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(displacement_map.cpu(), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask.cpu(), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(texture[0].cpu())\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_idx = 72\n",
    "img_size = (1080, 1920)\n",
    "render_res = (int(1080/3), int(1920/3))\n",
    "\n",
    "# Extract camera parameters and construct camera\n",
    "R, T, f, p = get_camera_parameters(subject, cam_idx)\n",
    "cameras = PerspectiveCameras(focal_length=-f, principal_point=p, R=R, T=T, in_ndc=False, image_size=(img_size,), device=device)\n",
    "\n",
    "# Segment person in photo from camera viewpoint\n",
    "photo_path = 'subject_%s/body/%s/image/image%s.jpg' % (subject, pose, str(cam_idx).zfill(7))\n",
    "photo, silh_photo, rgb_photo = get_pointrend_segmentation(photo_path, device=device)\n",
    "\n",
    "photo = photo[::3, ::3].to(device)\n",
    "silh_photo = silh_photo[0, ::3, ::3].float().to(device)\n",
    "rgb_photo = rgb_photo[0, ::3, ::3].to(device)\n",
    "\n",
    "# Construct mesh\n",
    "obj_mesh = load_obj(obj_path, load_textures=False)\n",
    "faces_uvs = obj_mesh[1].textures_idx.unsqueeze(0).to(device)\n",
    "verts_uvs = obj_mesh[2].verts_uvs.unsqueeze(0).to(device)\n",
    "texture_uv = TexturesUV(maps=texture, faces_uvs=faces_uvs, verts_uvs=verts_uvs)\n",
    "mesh = construct_textured_mesh(smplx_model, texture_uv, global_orient, transl, body_pose, left_hand_pose, right_hand_pose, jaw_pose, expression, betas, scale, subdivision, verts_disps)\n",
    "\n",
    "# Render mesh from camera viewpoint\n",
    "silhouette_renderer, phong_renderer = get_renderers(cameras, render_res, device=device)\n",
    "phong_render = phong_renderer(mesh).detach()\n",
    "silhouette_render = silhouette_renderer(mesh).detach()\n",
    "\n",
    "rgb_render = phong_render[0, ..., :3]\n",
    "silh_render = silhouette_render[0, ..., 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Image\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(photo.cpu())\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# RGB Render\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(rgb_render.cpu())\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# RGB Photo\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(rgb_photo.cpu())\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Mask Render\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(silh_render.cpu())\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Mask Photo\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(silh_photo.cpu())\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Save rgb color map as texture\n",
    "nrm_rgb_map = (texture[0].cpu().numpy() * 255.0).astype(np.uint8)\n",
    "Image.fromarray(nrm_rgb_map).save('test.png')\n",
    "\n",
    "# Save displacement map as texture\n",
    "nrm_disps_map = cv2.normalize(displacement_map.numpy(), None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "Image.fromarray(nrm_disps_map, mode='F').save('test.tiff')\n",
    "\n",
    "# Save geometry in npz file\n",
    "outfile = 'output_subject_%d.npz' % subject\n",
    "np.savez(outfile, body_pose=body_pose.numpy(), betas=betas.numpy(), scale=scale.numpy(), verts_disps=verts_disps.numpy(), learned_geometry=learned_geometry.numpy())\n",
    "\n",
    "# Loading npz file\n",
    "npzfile = np.load(outfile)\n",
    "npzfile.files # see all stored arrays in npz file\n",
    "npzfile['body_pose'] # call body_pose array stored into npz file"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pointcloud_rendering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
